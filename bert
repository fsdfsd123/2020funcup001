{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "step1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_it9YxKriXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import datetime\n",
        "starttime = datetime.datetime.now()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UrponPJGsRf4",
        "colab_type": "code",
        "outputId": "afd5df3a-1b1d-4518-a49b-5ed353694596",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "!export GOOGLE_APPLICATION_CREDENTIALS=\"My Project-ba13d9d9d219.json\"\n",
        "!pip install google.cloud.speech\n",
        "# [START speech_quickstart]\n",
        "import io\n",
        "import os\n",
        "\n",
        "# Imports the Google Cloud client library\n",
        "# [START speech_python_migration_imports]\n",
        "from google.cloud import speech\n",
        "from google.cloud.speech import enums\n",
        "from google.cloud.speech import types\n",
        "# [END speech_python_migration_imports]\n",
        "\n",
        "# Instantiates a client\n",
        "# [START speech_python_migration_client]\n",
        "\n",
        "client = speech.SpeechClient.from_service_account_json(\n",
        "      'My Project-ba13d9d9d219.json'\n",
        ")\n",
        "# [END speech_python_migration_client]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google.cloud.speech\n",
            "  Using cached https://files.pythonhosted.org/packages/fa/88/d48588464e8f88b0c8e6999cf32f75ddc43ff4ff1af4e21eb23a61b707fd/google_cloud_speech-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: google-api-core[grpc]<2.0.0dev,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from google.cloud.speech) (1.14.3)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (2018.9)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (3.10.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (1.4.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (2.21.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (1.6.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (1.12.0)\n",
            "Requirement already satisfied: setuptools>=34.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (41.6.0)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.8.2; extra == \"grpc\" in /usr/local/lib/python3.6/dist-packages (from google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (1.15.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (0.2.7)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (3.1.1)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (2019.9.11)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (1.24.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth<2.0dev,>=0.4.0->google-api-core[grpc]<2.0.0dev,>=1.14.0->google.cloud.speech) (0.4.7)\n",
            "Installing collected packages: google.cloud.speech\n",
            "Successfully installed google.cloud.speech\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_N2sLvqBnPnu",
        "colab_type": "code",
        "outputId": "f5c6f322-ffba-4203-ab35-63b5a78bd2c6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pydub\n",
            "  Downloading https://files.pythonhosted.org/packages/79/db/eaf620b73a1eec3c8c6f8f5b0b236a50f9da88ad57802154b7ba7664d0b8/pydub-0.23.1-py2.py3-none-any.whl\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.23.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfBb3OVdsAmp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "problemselect = []\n",
        "for i in range(1,101):\n",
        "        if(i<10):\n",
        "            index = '00'+repr(i)\n",
        "\n",
        "        if(i>10):\n",
        "            index = '0'+repr(i)\n",
        "        if(i==100):\n",
        "            index = repr(i)\n",
        "        sound = AudioSegment.from_mp3('C/C0000'+index+'.wav')\n",
        "        loudness = sound.dBFS\n",
        "        #print(loudness)\n",
        "\n",
        "        minsilence=450\n",
        "        chunks = split_on_silence(sound,\n",
        "            # must be silent for at least half a second,沉默半秒\n",
        "            min_silence_len=minsilence,\n",
        "        \n",
        "            # consider it silent if quieter than -16 dBFS\n",
        "            silence_thresh=-45,\n",
        "            keep_silence=400)\n",
        "        while(len(chunks)<4):\n",
        "            minsilence = minsilence-5\n",
        "            chunks = split_on_silence(sound,\n",
        "            # must be silent for at least half a second,沉默半秒\n",
        "            min_silence_len=minsilence,\n",
        "        \n",
        "            # consider it silent if quieter than -16 dBFS\n",
        "            silence_thresh=-45,\n",
        "            keep_silence=400)\n",
        "\n",
        "        while(len(chunks)>4):\n",
        "            minsilence = minsilence+5\n",
        "            chunks = split_on_silence(sound,\n",
        "            # must be silent for at least half a second,沉默半秒\n",
        "            min_silence_len=minsilence,\n",
        "        \n",
        "            # consider it silent if quieter than -16 dBFS\n",
        "            silence_thresh=-45,\n",
        "            keep_silence=400)\n",
        "        \n",
        "\n",
        "        if(len(chunks)!=4):\n",
        "          problemselect.append(i)\n",
        "\n",
        "        # # 放弃长度小于2秒的录音片段\n",
        "        # for i in list(range(len(chunks)))[::-1]:\n",
        "        #     if len(chunks[i]) <= 0 or len(chunks[i]) >= 10000:\n",
        "        #         chunks.pop(i)\n",
        "        # #print('取有效分段(大于2s小于10s)：', len(chunks))\n",
        "        \n",
        "\n",
        "        for i, chunk in enumerate(chunks):\n",
        "            if(len(chunks)==4):\n",
        "              chunk.export(\"Csplit/chunk\"+index+\"of\"+repr(i)+\".wav\" ,format=\"wav\")\n",
        "\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FO53vpHW281K",
        "colab_type": "code",
        "outputId": "cbf9a72a-100c-42b5-99d1-3478107fe716",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "problemselect"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BP1IYRjzsT1E",
        "colab_type": "code",
        "outputId": "2a2df902-3677-4993-8f57-2e08e85918d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "\n",
        "config = types.RecognitionConfig(\n",
        "        encoding=enums.RecognitionConfig.AudioEncoding.LINEAR16,\n",
        "        sample_rate_hertz=16000,\n",
        "        language_code='zh-tw',\n",
        "        audio_channel_count=1,\n",
        "        enable_automatic_punctuation=False\n",
        "        )\n",
        "\n",
        "print(config)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "encoding: LINEAR16\n",
            "sample_rate_hertz: 16000\n",
            "language_code: \"zh-tw\"\n",
            "audio_channel_count: 1\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpm8BcJcsVVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mP7qCFo2RaR_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd \n",
        "articlecsv = pd.read_csv(\"xunfei.csv\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_SRljYanbpa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from langconv import *\n",
        "\n",
        "from langconv import *\n",
        "\n",
        "def Simplified2Traditional(sentence):\n",
        "    '''\n",
        "    将sentence中的简体字转为繁体字\n",
        "    :param sentence: 待转换的句子\n",
        "    :return: 将句子中简体字转换为繁体字之后的句子\n",
        "    '''\n",
        "    sentence = Converter('zh-hant').convert(sentence)\n",
        "    return sentence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BGZiZQ96fvn",
        "colab_type": "code",
        "outputId": "b5e6cb6e-68d0-4dad-fb33-1a09755fc3a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#select\n",
        "article = []    \n",
        "question = []\n",
        "select = [[],[],[],[]]\n",
        "from pandas.core.frame import DataFrame\n",
        "\n",
        "for i in range(1,num+1):\n",
        "\n",
        "  if(i<10):\n",
        "      index = '00'+repr(i)\n",
        "  if(i>10):\n",
        "      index = '0'+repr(i)\n",
        "  if(i==100):\n",
        "      index = repr(i)   \n",
        "\n",
        "  for j in range(0,3):\n",
        "\n",
        "    if(j!=2):\n",
        "        if(j==0):\n",
        "          file = 'A'\n",
        "          article.append(articlecsv['article'][i-1])\n",
        "\n",
        "        if(j==1):\n",
        "          file = 'B'\n",
        "          file_name = os.path.join(\n",
        "          os.path.dirname('__file__'),\n",
        "          file,\n",
        "          file+'0000'+index+'.wav')\n",
        "          \n",
        "          with io.open(file_name, 'rb') as audio_file:\n",
        "              content = audio_file.read()\n",
        "              audio = types.RecognitionAudio(content=content)\n",
        "          response = client.recognize(config, audio)\n",
        "\n",
        "        \n",
        "          for result in response.results:\n",
        "            # if(j==0):\n",
        "            #   article.append(result.text)\n",
        "            if(j==1):\n",
        "              question.append(Simplified2Traditional(result.alternatives[0].transcript))\n",
        "              #question.append(result.alternatives[0].transcript)\n",
        "\n",
        "    if(j==2):\n",
        "      file = 'Csplit'\n",
        " \n",
        "      else:\n",
        "        for k in range(0,4):\n",
        "            if(i in problemselect):\n",
        "              select[k].append('error')\n",
        "              \n",
        "            file_name = os.path.join(\n",
        "              os.path.dirname('__file__'),\n",
        "              file,\n",
        "              'chunk'+index+'of'+repr(k)+'.wav')\n",
        "            #print(file_name)\n",
        "            with io.open(file_name, 'rb') as audio_file:\n",
        "              content = audio_file.read()\n",
        "              audio = types.RecognitionAudio(content=content)\n",
        "              #print(type(audio))\n",
        "            response = client.recognize(config, audio)\n",
        "            for result in response.results:\n",
        "              select[k].append(Simplified2Traditional(result.alternatives[0].transcript))\n",
        "              #select[k].append(result.alternatives[0].transcript)\n",
        "            \n",
        "\n",
        "      \n",
        "\n",
        "  if(len(article)==len(question)==len(select[0])):\n",
        "    c={\n",
        "      \"0\" : article,\n",
        "      \"1\" : question,\n",
        "      '2' : select[0],\n",
        "      '3' : select[1],\n",
        "      \"4\" : select[2],\n",
        "      \"5\" : select[3],\n",
        "\n",
        "      }\n",
        "      #将列表a，b转换成字典\n",
        "    fsddata=DataFrame(c)#将字典转换成为数据框\n",
        "    print(len(fsddata))\n",
        "    fsddata.to_csv(path_or_buf=\"soundresult.csv\",encoding='UTF-8',index=False)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcYE0Mi-2KdH",
        "colab_type": "code",
        "outputId": "2e6ffa8b-ec2f-44ef-f837-7eeef0e97075",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        }
      },
      "source": [
        "!pip install https://github.com/huggingface/transformers/releases/download/v0.1.2/pytorch_pretrained_bert-0.1.2.tar.gz"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting https://github.com/huggingface/transformers/releases/download/v0.1.2/pytorch_pretrained_bert-0.1.2.tar.gz\n",
            "\u001b[?25l  Downloading https://github.com/huggingface/transformers/releases/download/v0.1.2/pytorch_pretrained_bert-0.1.2.tar.gz (46kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 275kB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.1.2) (1.3.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.1.2) (1.17.4)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.1.2) (1.10.18)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.1.2) (2.21.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch-pretrained-bert==0.1.2) (4.28.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.1.2) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.1.2) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.18 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch-pretrained-bert==0.1.2) (1.13.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.1.2) (2019.9.11)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.1.2) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.1.2) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch-pretrained-bert==0.1.2) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->pytorch-pretrained-bert==0.1.2) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.18->boto3->pytorch-pretrained-bert==0.1.2) (0.15.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\"->botocore<1.14.0,>=1.13.18->boto3->pytorch-pretrained-bert==0.1.2) (1.12.0)\n",
            "Building wheels for collected packages: pytorch-pretrained-bert\n",
            "  Building wheel for pytorch-pretrained-bert (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-pretrained-bert: filename=pytorch_pretrained_bert-0.1.2-cp36-none-any.whl size=32311 sha256=75067be3604a3e63992fbbadd967d76f26e124b213d094e828d0913d786bec51\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/f2/55/b2c19f6d3a9bbede0fb2d8874b33510e5fe96f33a8549166c9\n",
            "Successfully built pytorch-pretrained-bert\n",
            "Installing collected packages: pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.1.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKz_P9QJ2Mlk",
        "colab_type": "code",
        "outputId": "4c60219a-3a5a-4ae2-bce1-cf95ed5a8f31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "!nvidia-smi\n",
        "!rm -rf bert_chinese*\n",
        "!rm -rf pytorch_pretrained_bert*\n",
        "!wget -q --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1SXz4Hr073OCuIOqzmi1Ool6m9-g8yYOf' -O bert_chinese.zip\n",
        "!unzip -q -o bert_chinese.zip\n",
        "!wget -q --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=15vkVWzKDlik_l2MAkvGI6tIhPauQiGaW' -O pytorch_pretrained_bert.zip\n",
        "!unzip -q -o pytorch_pretrained_bert.zip\n",
        "# !wget --no-check-certificate -r 'https://drive.google.com/uc?export=download&id=1IIVjgGX_JeXBNQv-vRAj1JLFvv2x9EVu' -O pytorch_pretrained_bert-0.1.2.zip\n",
        "# !unzip pytorch_pretrained_bert-0.1.2.zip\n",
        "# %cd pytorch_pretrained_bert-0.1.2\n",
        "# !python setup.py install\n",
        "# %cd .."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fri Nov 29 15:31:29 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.33.01    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "warning [bert_chinese.zip]:  401075 extra bytes at beginning or within zipfile\n",
            "  (attempting to process anyway)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHH23TK42PUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import (DataLoader, RandomSampler, SequentialSampler,\n",
        "                              TensorDataset)\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def to_list(tensor):\n",
        "    return tensor.detach().cpu().tolist()\n",
        " \n",
        "\n",
        "def _get_best_indexes(logits, n_best_size=1):\n",
        "    \"\"\"Get the n-best logits from a list.\"\"\"\n",
        "    index_and_score = sorted(enumerate(logits), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    best_indexes = []\n",
        "    for i in range(len(index_and_score)):\n",
        "        if i >= n_best_size:\n",
        "            break\n",
        "        best_indexes.append(index_and_score[i][0])\n",
        "    return best_indexes\n",
        " \n",
        "def softmax(x):\n",
        "    e_x = np.exp(x - np.max(x))\n",
        "    return e_x / e_x.sum(axis=1, keepdims=True)\n",
        "    \n",
        "def predict(eval_dataloader, model, tokenizer, device='cpu'):\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "    predictions = []\n",
        "    for input_ids, input_mask, segment_ids, label_ids in tqdm(eval_dataloader, desc='Iteration'):\n",
        "        input_ids = input_ids.to(device)\n",
        "        input_mask = input_mask.to(device)\n",
        "        segment_ids = segment_ids.to(device)\n",
        "        label_ids = label_ids.to(device)\n",
        "\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            print(input_ids.shape)\n",
        "#             tmp_eval_loss, logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "            logits = model(input_ids, segment_ids, input_mask, label_ids)\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = label_ids.to('cpu').numpy()\n",
        "        \n",
        "        logits = softmax(logits.tolist())\n",
        "        for logit in logits:\n",
        "            predictions.append(logit)\n",
        "\n",
        "    return np.argmax(predictions[0])\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz_Nass92QnJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import collections\n",
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id\n",
        "\n",
        "        \n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "            \n",
        "            \n",
        "def convert_examples_to_features(context, question, choices, tokenizer, ans, max_seq_length=300, label_list=[1,2,3,4]):\n",
        "    \n",
        "    text_bs = list()\n",
        "    for choice in choices:\n",
        "        # text_b = tokenization.convert_to_unicode(str(row['choice%d' % i]))\n",
        "        text_bs.append(\"{} {}\".format(question, choice))\n",
        "        #text_b.append(choice)\n",
        "      \n",
        "\n",
        "    label_map = {}\n",
        "    for (i, label) in enumerate(label_list):\n",
        "        label_map[label] = i    \n",
        "\n",
        "    multiple_choice_input_ids = []\n",
        "    multiple_choice_input_masks = []\n",
        "    multiple_choice_segment_ids = []\n",
        "    for text_b in text_bs:  \n",
        "    \n",
        "\n",
        "        tokens_a = tokenizer.tokenize(context)  \n",
        "\n",
        "        tokens_b = None\n",
        "        if text_b:\n",
        "            tokens_b = tokenizer.tokenize(text_b)   \n",
        "\n",
        "        if tokens_b:\n",
        "            # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "            # length is less than the specified length.\n",
        "            # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "            _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "        else:\n",
        "            # Account for [CLS] and [SEP] with \"- 2\"\n",
        "            if len(tokens_a) > max_seq_length - 2:\n",
        "                tokens_a = tokens_a[0:(max_seq_length - 2)] \n",
        "\n",
        "        \n",
        "        tokens = []\n",
        "        segment_ids = []\n",
        "        tokens.append(\"[CLS]\")\n",
        "        segment_ids.append(0)\n",
        "        for token in tokens_a:\n",
        "            tokens.append(token)\n",
        "            segment_ids.append(0)\n",
        "        tokens.append(\"[SEP]\")\n",
        "        segment_ids.append(0)   \n",
        "\n",
        "        if tokens_b:\n",
        "            for token in tokens_b:\n",
        "                tokens.append(token)\n",
        "                segment_ids.append(1)\n",
        "            tokens.append(\"[SEP]\")\n",
        "            segment_ids.append(1)   \n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens) \n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1] * len(input_ids)   \n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        while len(input_ids) < max_seq_length:\n",
        "            input_ids.append(0)\n",
        "            input_mask.append(0)\n",
        "            segment_ids.append(0)   \n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        multiple_choice_input_ids.append(input_ids)\n",
        "        multiple_choice_input_masks.append(input_mask)\n",
        "        multiple_choice_segment_ids.append(segment_ids)\n",
        "    assert len(multiple_choice_input_ids) == 4\n",
        "    assert len(multiple_choice_input_masks) == 4\n",
        "    assert len(multiple_choice_segment_ids) == 4    \n",
        "\n",
        "    label_id = label_map[ans] \n",
        "    \n",
        "    \n",
        "\n",
        "    f = InputFeatures(input_ids=multiple_choice_input_ids,\n",
        "                      input_mask=multiple_choice_input_masks,\n",
        "                      segment_ids=multiple_choice_segment_ids,\n",
        "                      label_id=label_id)  \n",
        "    \n",
        "    \n",
        "\n",
        "    all_input_ids = torch.tensor([f.input_ids], dtype=torch.long)\n",
        "    all_input_mask = torch.tensor([f.input_mask], dtype=torch.long)\n",
        "    all_segment_ids = torch.tensor([f.segment_ids], dtype=torch.long)\n",
        "    all_label_ids = torch.tensor([f.label_id], dtype=torch.long)\n",
        "    eval_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "    eval_dataloader = DataLoader(eval_data, sampler=SequentialSampler(eval_data), batch_size=1)\n",
        "\n",
        "    return eval_dataloader, tokens\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wae56JKq2R0c",
        "colab_type": "code",
        "outputId": "a93a603a-be09-4899-8b3c-2fb45b597273",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "source": [
        "# 因為要我們今天要跑的是中文QA 所以只有Bert可以用\n",
        "import torch\n",
        "from pytorch_pretrained_bert import (BertConfig, BertForSequenceClassification,\n",
        "                                 BertTokenizer)\n",
        "\n",
        "device = torch.device(\"cuda\")\n",
        " \n",
        "model_name = 'bert_chinese'\n",
        "config_class, tokenizer_class = BertConfig, BertTokenizer\n",
        "# model = model_class.from_pretrained('bert_chinese').to(device)\n",
        "model = torch.load(model_name + '/model.cpt') \n",
        "tokenizer = torch.load(model_name + '/tokenizer.cpt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'pytorch_pretrained_bert.modeling.BertForSequenceClassification' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.sparse.Embedding' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.dropout.Dropout' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.container.ModuleList' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.linear.Linear' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:493: SourceChangeWarning: source code of class 'torch.nn.modules.activation.Tanh' has changed. you can retrieve the original source code by accessing the object's source attribute or set `torch.nn.Module.dump_patches = True` and use the patch tool to revert the changes.\n",
            "  warnings.warn(msg, SourceChangeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QhI_VHdg2T3g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import pandas as pd \n",
        "#soundresult = pd.read_csv(\"soundresult.csv\") \n",
        "#trueanswer = pd.read_csv(\"trueanswer.csv\") \n",
        "#soundresult = trueanswer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCaauIWQ2oGP",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHqSwx9j2Vcr",
        "colab_type": "code",
        "outputId": "3167a045-36c2-4dd9-bad0-d2947a00951e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "num=100\n",
        "import pandas as pd \n",
        "final = []\n",
        "soundresult = pd.read_csv(\"soundresult.csv\") \n",
        "column= ['2','3','4','5']\n",
        "count1 = ['1','2','3','4']\n",
        "count2 = ['一','二','三','四']\n",
        "for i in range(0,num):\n",
        "  context = soundresult['0'][i]\n",
        "  question = soundresult['1'][i]\n",
        "  #choices=[soundresult['2'][i],soundresult['3'][i],soundresult['4'][i],soundresult['5'][i]]\n",
        "  \n",
        "  choices = []\n",
        "\n",
        "  for j in range(0,4):\n",
        "    #choices.append((soundresult[column[j]][i])[1:])\n",
        "    if((soundresult[column[j]][i][0:1])==count1[j]or(soundresult[column[j]][i])[0:1]==count2[j]): \n",
        "      choices.append((soundresult[column[j]][i])[1:])\n",
        "    else:  \n",
        "     choices.append((soundresult[column[j]][i]))\n",
        "  label = 3\n",
        "  data, tokens = convert_examples_to_features(context, question, choices, tokenizer, 2)\n",
        "  pred = predict(data, model, tokenizer, device=device)\n",
        "  final.append(pred+1)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rIteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  2.31it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  3.67it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.07it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.27it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.46it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.42it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.43it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.29it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.41it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.40it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.28it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.38it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.37it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.30it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.34it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.39it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.36it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.32it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.44it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.35it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Iteration: 100%|██████████| 1/1 [00:00<00:00,  4.33it/s]\n",
            "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 4, 300])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rIteration: 100%|██████████| 1/1 [00:00<00:00,  4.31it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fD1NPHdQ3UGJ",
        "colab_type": "code",
        "outputId": "7226790f-6c05-4e67-8453-ef5e6ed8177a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(final)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CeMAOMoH2YZ9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# score = 0\n",
        "# wrong = [\n",
        "#          [],[],[],[],[],[]\n",
        "#          ]\n",
        "# for i in range(0,100):\n",
        "  \n",
        "#   if(final[i]==int(trueanswer['答案'][i])):\n",
        "#     score=score+1\n",
        "#   if(final[i]!=int(trueanswer['答案'][i])):  \n",
        "#     print(final[i])\n",
        "    #print(soundresult.iloc[i, [0,1,2,3,4,5]])\n",
        "    #print(trueanswer['tr'][i])\n",
        "    #print(trueanswer.iloc[i, [1,2,3,4,5,6]])\n",
        "    # wrong[0].append(soundresult[0][i])\n",
        "    # wrong[1].append(soundresult[1][i])\n",
        "    # for j in range(0,4):\n",
        "    #   wrong[j+2].append(soundresult[column[j]][i])\n",
        "    #print(soundresult['0'][i]+soundresult['1'][i]+soundresult['2'][i]+soundresult['3'][i]+soundresult['4'][i]+soundresult['5'][i])\n",
        "    #print(i)\n",
        "      #wrong.append(soundresult[j][i])\n",
        "      #wrong.append(trueanswer[j][i])\n",
        "    \n",
        "print(score)\n",
        "# for i in range(0,6):\n",
        "#   print(wrong[i])\n",
        "# if(wrong[0]==wrong[1]==wrong[2]==wrong[3]==wrong[4]==wrong[5]):\n",
        "#   c={\n",
        "#     \"0\" : wrong[0],\n",
        "#     \"1\" : wrong[1],\n",
        "#     '2' : wrong[2],\n",
        "#     '3' : wrong[3],\n",
        "#     \"4\" : wrong[4],\n",
        "#     \"5\" : wrong[5],\n",
        "\n",
        "#     }\n",
        "    \n",
        "#     #将列表a，b转换成字典\n",
        "#   from pandas.core.frame import DataFrame\n",
        "#   fsddata=DataFrame(c)#将字典转换成为数据框\n",
        "#   print(len(fsddata)+'%')\n",
        "#   fsddata.to_csv(path_or_buf=\"wrong.csv\",encoding='UTF-8',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_267anv2Zj5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pandas.core.frame import DataFrame\n",
        "finaldict = {\n",
        "    \"ID\":range(1,101),\n",
        "    \"Answer\":final\n",
        "    }\n",
        "finaldataframe=DataFrame(finaldict)#将字典转换成为数据框\n",
        "\n",
        "finaldataframe.to_csv(path_or_buf=\"final.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhgwOOz2rlbf",
        "colab_type": "code",
        "outputId": "797310e4-96a6-48ec-f070-a87ef9f803a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#long running\n",
        "endtime = datetime.datetime.now()\n",
        "print (endtime - starttime)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0:13:01.022233\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}